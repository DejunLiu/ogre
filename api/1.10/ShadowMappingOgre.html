<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<title>OGRE: Shadow Mapping in Ogre</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
  $(window).load(resizeHeight);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="ogre_style.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="ogre-logo-wetfloor.gif"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">OGRE
   &#160;<span id="projectnumber">1.10.10</span>
   </div>
   <div id="projectbrief">Object-Oriented Graphics Rendering Engine</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('ShadowMappingOgre.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">Shadow Mapping in Ogre </div>  </div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul><li class="level1"><a href="#ShadowMappingIntro">Introduction to the Shadow Mapping Algorithm</a><ul><li class="level2"><a href="#sm_formalism">Formalism</a></li>
<li class="level2"><a href="#DepthBias">Depth Biasing</a></li>
<li class="level2"><a href="#sm_pcm">Percentage Closest Filtering</a></li>
</ul>
</li>
<li class="level1"><a href="#sm_variants">Variants</a><ul><li class="level2"><a href="#sm_additional_info">Storing Additional Info</a></li>
<li class="level2"><a href="#sm_breaking_frusta">Breaking up Shadow Frusta</a></li>
<li class="level2"><a href="#sect_planeopt">Playing with Projection Matrices</a></li>
</ul>
</li>
<li class="level1"><a href="#sm_theory">Theory and Analysis</a><ul><li class="level2"><a href="#sm_nonopt">(Non)Optimality of Logarithmic Shadow Maps</a></li>
<li class="level2"><a href="#sm_aliasing">Sampling Aliasing versus Depth Precision Aliasing</a></li>
<li class="level2"><a href="#sm_proj_aliasing">Projective versus Perspective Aliasing</a></li>
</ul>
</li>
<li class="level1"><a href="#Implementation">Implementation</a></li>
</ul>
</div>
<div class="textblock"><h1><a class="anchor" id="ShadowMappingIntro"></a>
Introduction to the Shadow Mapping Algorithm</h1>
<p>Shadow mapping, an algorithm introduced by Lance Williams  <a class="el" href="citelist.html#CITEREF_WIL78">[9]</a> and now prevalent in real-time and off-line rendering, is based on a simple idea: First, a snapshot of the scene is taken from the viewpoint of the light. Then, when creating an image from the perspective of the camera, the light’s snapshot is used to determine visibility. Parts of the scene seen by both the light and the camera must be lit (by the light in question). Parts of the scene visible only to the camera must be shadowed. We do not care about parts of the scene seen only by the light.</p>
<p>In practice, the snapshot from the viewpoint of the light is stored as a floating point depth buffer. It is important to use a format that supports enough precision to avoid shadow acne (z-fighting) on lit surfaces. In <a class="el" href="namespace_ogre.html" title=" This source file is part of OGRE (Object-oriented Graphics Rendering Engine) For the latest info...">Ogre</a>, we can specify the depth format to use; in the example code, we will choose the 32-bit format.</p>
<p>Once shadow determination has occurred (whether a fragment is in shadow or not), <a class="el" href="namespace_ogre.html" title=" This source file is part of OGRE (Object-oriented Graphics Rendering Engine) For the latest info...">Ogre</a> provides two different ways to render the shadows into the final image. The modulative technique will uniformly darken regions of the image determined to be in shadow. This is a cheaper and less accurate lighting model. For instance, specular highlights in shadow will appear as darkened specular highlights. The other technique is additive light masking. This technique builds up contributions from each light in non-shadowed areas and adds them together to create the final image. The code in section <a class="el" href="ShadowMappingOgre.html#Implementation">Implementation</a> will use additive light masking, but could just as easily be adapted for modulative shadows.</p>
<h2><a class="anchor" id="sm_formalism"></a>
Formalism</h2>
<p>Mathematically, the process can be represented as follows: Let \(P_l\) and \(P_c\) be the projection matrices for the light and camera respectively. Let \(M_l\) and \(M_c\) be the modelview matrices for the light and camera coordinate systems. Let \(\vec{x} = [x_1,x_2,x_3,1]^t\) be a point in object space, \(\vec{y} = [y_1,y_2,y_3,1]^t\) the screen space coordinates, and \(\vec{u} = [u_1,u_2,u_3,1]^t\) the shadow map coordinates.</p>
<p class="formulaDsp">
\[ \begin{aligned} \left[ \begin{array}{c} u_1 w_l \\ u_2 w_l \\ u_3 w_l \\ w_l \end{array} \right] = P_l M_l \left[ \begin{array}{c} x_1 \\ x_2 \\ x_3 \\ 1 \end{array} \right]\end{aligned} \]
</p>
<p class="formulaDsp">
\[\begin{aligned} \left[ \begin{array}{c} y_1 w_c \\ y_2 w_c \\ y_3 w_c \\ w_c \end{array} \right] = P_c M_c \left[ \begin{array}{c} x_1 \\ x_2 \\ x_3 \\ 1 \end{array} \right]\end{aligned}\]
</p>
<p>These equations can be written more concisely as: \(\vec{u}w_l = P_l M_l \vec{x}\) and \(\vec{y} w_c = P_c M_c \vec{x}\). Division of \(\vec{u}w_l\) and \(\vec{y}w_c\) by their respective homogeneous coordinates yields the Euclidean representations \(\vec{u}\) and \(\vec{y}\).</p>
<p>Note that while \(P_c\) and \(M_c\) are completely determined by the camera image we want to produce, we have some ambiguity in the \(P_l\) and \(M_l\) chosen for shadow mapping. The degrees of freedom here are later exploited to combat the aliasing issue.</p>
<h2><a class="anchor" id="DepthBias"></a>
Depth Biasing</h2>
<div class="image">
<img src="depthbias.svg" alt="depthbias.svg"/>
<div class="caption">
Shadow map sample must use one float to represent a range of possible depth values. A depth sample is chosen in the middle. Any camera image point in between the two camera rays will see the geometry, and depending on distance from light will report differently on shadowed versus lit. However, every such point should be lit.</div></div>
<p>Due to the finite precision of floating point representations and inherent inability of one number to represent a range of values, it is often necessary to add a little bias to the depth values stored in a shadow map. One does not simply store the \(u_3\) value. Figure [fig:bias] illustrates the issue. Here we have used blue dots on the light’s image plane to represent boundaries between shadow “texels.” The interval in between the dots then represents a shadow map sample for which a single depth value (float) is stored. For the sample whose boundary rays are shown, the red dot’s depth is saved. However, note that from the camera’s perspective, any (camera) image point in between the two drawn camera rays will hit the scene geometry within the shadow map sample’s interval. Hence, the same shadow map sample depth will be used to determine visibility for all such camera pixels. Camera pixels whose rays fall to the right of the red dot will be marked as shadowed, while pixels whose rays fall to the left of the red dot will be marked as lit. This is not the right behavior because clearly all the pixels should be marked as lit. As we can see, a depth bias is needed. By pushing the shadow map sample’s depth farther (to the 2nd red dot), we can achieve correct shadow determination.</p>
<p>One could approach the depth bias issue in a completely <span>*ad hoc*</span> manner, but it is possible to do better. One would ideally compute a bias that depends on how depth ( \(u_3\)) changes between shadow map samples. The change in depth as one moves a unit step (to the next shadow map sample) represents the ambiguity of the depth value. Such a value may seem intractable to compute, but calculus and linear algebra save the day. From calculus, we learn that the derivative provides the best linear approximation to any function ( \(u_3 = u_3(u_1, u_2)\) in particular). In multiple dimensions, this role is played by the Jacobian (matrix of partial derivatives). In other words, we want to compute \(\frac{du_3}{du_1}\) and \(\frac{du_3}{du_2}\), where we have treated \(u_3\) as a function of \(u_1\) and \(u_2\). Once these values are computed, it makes sense to then add some weighted combination of these to the stored depth value (e.g., some scale of the Jacobian’s Frobenius norm).</p>
<p>But even if the light is staring at a plane straight on (view direciton lines up with plane’s normal), making \(\frac{du_3}{du_1}\) and \(\frac{du_3}{du_2}\) both zero, we would still need a slight offset because rounding due to the float’s finite representation may still cause shadow acne. In this case, we’d like to offset the depth by a small value that pushes it beyond rounding ambiguity. While one could use an arbitrary constant offset, this is unsatisfactory since the constant in light image space corresponds to varying amounts of offset in light space (pre-projection Euclidean space with light’s position at origin). Let us instead choose a constant offset in the z direction of <span>*light space*</span> and compute what the offset for a particular sample should be in <span>*light image space*</span>. In Ogre’s example code, the small constant offset in light space is chosen to be 1 unit. If 1 is not a small amount in your engine’s chosen scale, you can easily change this choice. At any rate, the relevant quantity is \(\frac{\partial u_3}{\partial X_3}\) where \(\vec{X} = M_l \vec{x}\).</p>
<p>The choices here closely mirror what OpenGL implements through glPolygonOffset. The second adjustment is slightly different since OpenGL chooses a vendor specific fudge factor.</p>
<p>Equations for computing the stated quantities are provided below. One need not wade through these to use the depth biasing code. Understanding what the relevant parameters explained above are (in case adjustment is needed) is sufficient.</p>
<p class="formulaDsp">
\[\begin{aligned} \label{eqn:dxqdu} \frac{\partial (\vec{x} q_l)}{\partial u_i} = \mbox{i-th column of } M_l^{-1} P_l^{-1} V_l^{-1} \end{aligned}\]
</p>
<p>where \(V_l\) is the viewport matrix for the light and \(i=1,2,3\). \(q_l\) turns out to be \(1/w_l\).</p>
<p class="formulaDsp">
\[\begin{aligned} \label{eqn:dxdu} \frac{\partial \vec{x}}{\partial u_i} = \frac{1}{q_l} \left( \frac{\partial (\vec{x} q_l)}{\partial u_i} - \vec{x}\frac{\partial q_l}{\partial u_i} \right) \\ \label{eqn:du3du} \frac{du_3}{du_j} = \left( \vec{n} \cdot \frac{\partial \vec{x}}{\partial u_3} \right)^{-1} \left( \vec{n} \cdot \frac{\partial \vec{x}}{\partial u_j} \right)\end{aligned}\]
</p>
<p>where \(\vec{n}\) is the normal at point \(\vec{x}\) and \(j=1,2\). Note that ([eqn:du3du]) is exactly the set of values needed for the first part.</p>
<p class="formulaDsp">
\[\begin{aligned} \label{eqn:duwdX3} \frac{\partial (\vec{u} w_l)}{\partial X_3} = \mbox{3rd column of } P_l \\ \label{eqn:dudX3} \frac{\partial \vec{u}}{\partial X_3} = \frac{1}{w_l} \left( \frac{\partial (\vec{u} w_l)}{\partial X_3} - \vec{u}\frac{\partial w_l}{\partial X_3} \right)\end{aligned}\]
</p>
<p>Note that ([eqn:dudX3]) is the quantity needed for the second bias term. This is also the term to scale for different choices of small offset in light space. If 0.01 units is the small offset, scale this value by 0.01.</p>
<h2><a class="anchor" id="sm_pcm"></a>
Percentage Closest Filtering</h2>
<p>As widely known, shadow mapping can exhibit significant aliasing. When this happens during texture mapping we apply filtering. We’d like to apply a similar principle with shadow maps, but filtering depth values is categorically the wrong thing to do. As described in  <a class="el" href="citelist.html#CITEREF_RSC87">[7]</a>, one should instead filter depth test results. This is termed percentage closest filtering. Ideally this would be a filtering technique much like anisotropic texture filtering, but for simplicity and efficiency, Ogre’s example code implements the bilinear analogue.</p>
<h1><a class="anchor" id="sm_variants"></a>
Variants</h1>
<p>There are many shadow mapping variants. Enumerating (much less describing) all of them would take us too far afield in this article. We instead defer to the provided references and google for such coverage. The many variants can, however, be broken up into three broad categories:</p><ol type="1">
<li>Those that store additional information beyond a single float,</li>
<li>those that divide up shadow frusta into multiple frusta to be handled separately, and</li>
<li>those that propose less naive \(P_l\) and \(M_l\) to use and thereby affect the sampling distribution.</li>
</ol>
<p>Algorithms in each category usually work quite independently and so many hybrid approaches are easily conceivable.</p>
<h2><a class="anchor" id="sm_additional_info"></a>
Storing Additional Info</h2>
<p>One example of this is Deep Shadow Maps  <a class="el" href="citelist.html#CITEREF_LV00">[5]</a>. In this work, instead of storing a single depth value and treating visibility as a binary value, a transfer function is stored and visibility is continuous. This algorithm is important in offline movie rendering, but also relevant to the Variance Shadow Mapping algorithm elucidated by the game developer community  <a class="el" href="citelist.html#CITEREF_DL06">[3]</a>.</p>
<p>While variance shadow maps are motivated by statistical considerations, it is perhaps more properly understood in the Deep Shadow Maps framework. Analyzing it in terms of distributions is flawed for two reasons:</p><ol type="1">
<li>the inequality considered is valid only for unimodal distributions whereas depth values are often discontinuous in regions that matter;</li>
<li>the inequality is treated as equality. The equations are justified with a very specific example in which two planes are viewed straight on. In practice there are very noticeable halo effects around objects, which makes more heuristic tweaks necessary.</li>
</ol>
<p>Recasting this into the framework of deep shadow maps, we see that the proposed equality is simply a particular functional approximation to the transfer function. Variance shadow maps proposes a two-parameter family of approximation functions whose parameters are linearly interpolated in the usual way. This viewpoint allows for analysis and also suggests the possibility of getting improvements via other approximating functional forms.</p>
<h2><a class="anchor" id="sm_breaking_frusta"></a>
Breaking up Shadow Frusta</h2>
<p>Adaptive Shadow Maps  <a class="el" href="citelist.html#CITEREF_FFB01">[4]</a> are an example of this. It is still largely considered too expensive for real-time rendering, but continued research and growing GPU power may make some variant worthwhile.</p>
<h2><a class="anchor" id="sect_planeopt"></a>
Playing with Projection Matrices</h2>
<p>There are various heuristic approaches for choosing \(P_l\) and \(M_l\), but here we will focus on one method, the Plane Optimal algorithm  <a class="el" href="citelist.html#CITEREF_Chong04">[1]</a>, that provides a particular guarantee. For this algorithm, we specify a plane of interest (e.g., ground plane, wall, table top) for which we want perfect shadowing no matter the configuration of light and camera in the scene (even dueling frusta). The algorithm will then compute \(P_l\) and \(M_l\) so that the mapping between camera image and light image is the identity when restricted to the plane. If the shadow map matches the resolution of the screen, then each pixel gets exactly one shadow sample. Shadows off the plane of interest have no guarantees. One limitation of the method is shown in Figure [fig:planeopt]. Only region I will be shadowed and self-shadowed properly, with points on the plane being shadowed perfectly (alias-free). This makes the method perhaps most useful for games where the view is top-down or isometric (like RTS games). It is also useful for cases like dueling frusta (where just about all other methods fail).</p>
<div class="image">
<img src="optfrust.svg" alt="optfrust.svg"/>
<div class="caption">
Region I is defined as the set of all points along rays between the light and a point on the plane of interest in the camera’s view. Everything in region I is shadowed and self-shadowed properly. Objects in region II are not self-shadowed properly.</div></div>
<h1><a class="anchor" id="sm_theory"></a>
Theory and Analysis</h1>
<p>A full discussion of shadow map analysis is beyond the scope of this article. For those interested, the references  <a class="el" href="citelist.html#CITEREF_Chong06">[2]</a> and  <a class="el" href="citelist.html#CITEREF_Chong04">[1]</a> are good (in my extremely biased opinion). Note that as research papers, they are quite concise. Unfortunately there don’t seem to more step-by-step expositions available at this moment.</p>
<p>There has been a lot of academic and industry research on improving shadow maps. However, analyses presented on shadow maps often do not say what people claim they say. These faulty conclusions usually come from considering very special cases and assuming the general case is very similar. For clarification, we explore some of these misconceptions here.</p>
<h2><a class="anchor" id="sm_nonopt"></a>
(Non)Optimality of Logarithmic Shadow Maps</h2>
<p>We start with one <em>heuristic</em> that has gained quite a bit of traction: the idea of using some logarithmic mapping between light space and light image space instead of a projective transform. A number of algorithms based on this idea have been proposed, and even some hardware changes. Much of this work seems to be motivated by the incorrect assumption that logarithmic mappings are optimal.</p>
<p>The very special motivating case is this: The camera looks down the z axis. Directional light illuminates the scene perpendicular to the z axis. An angled piece of a plane is viewed by the camera. As the angled piece of plane is pulled along the camera ray direction, using a logarithmic shadow map gives us constant shadow quality on this geometric piece. But unless we’re rendering translucent dust particles along a camera ray, this analysis is irrelevant. If the dust particles are not translucent, we only care about shadow determination on the first one, not a whole line of them. If we are rendering continuous surfaces (resp. curves), we care about the quality as one moves in the tangent plane (resp. tangent) direction because this is the best linear approximation to the surface (resp. curve), not the camera ray direction.</p>
<p>In fact, in the case of a chosen plane of interest for example, we know we can get completely alias free shadow mapping using a projective transform (section <a class="el" href="ShadowMappingOgre.html#sect_planeopt">Playing with Projection Matrices</a>). Logarithmic shadow maps may be an interesting heuristic to try out, but certainly not worth changing hardware over in my opinion. If you’re going to change hardware, might as well aim for true optimality.</p>
<h2><a class="anchor" id="sm_aliasing"></a>
Sampling Aliasing versus Depth Precision Aliasing</h2>
<p>Sometimes people tend to conflate these two sources of aliasing. They note that after applying some sort of custom projective transform, the depth values are warped as well. This problem can be completely overcome via the depth replacement method prescribed in Trapezoidal Shadow Maps  <a class="el" href="citelist.html#CITEREF_MT04">[6]</a>. So this is a completely orthogonal issue. Depth precision can be just as good as “normal” shadow maps, no matter the perspective warp used to affect sampling.</p>
<h2><a class="anchor" id="sm_proj_aliasing"></a>
Projective versus Perspective Aliasing</h2>
<p>The terms perspective and projective aliasing appeared in the Perspective Shadow Maps  <a class="el" href="citelist.html#CITEREF_SD02">[8]</a> paper and has since been used extensively by those who work on improving shadow heuristics. Often it is claimed that methods ameliorate perspective aliasing while projective aliasing is either unavoidable or must be addressed via completely separate means. However, the distinction between the two is somewhat artificial. Both result from not allocating enough shadow map samples to regions that matter to the viewer. As the Plane Optimal algorithm demonstrates, it is possible to completely remove projective aliasing (as well as perspective aliasing) in certain scenes. In general, there should be one combined measure of aliasing and algorithms must minimize this quantity. See  <a class="el" href="citelist.html#CITEREF_Chong06">[2]</a> for a unified notion of aliasing.</p>
<h1><a class="anchor" id="Implementation"></a>
Implementation</h1>
<p><a class="el" href="namespace_ogre.html" title=" This source file is part of OGRE (Object-oriented Graphics Rendering Engine) For the latest info...">Ogre</a> provides a powerful framework that allows us to do a lot of shadow map customization. In <a class="el" href="namespace_ogre.html" title=" This source file is part of OGRE (Object-oriented Graphics Rendering Engine) For the latest info...">Ogre</a>, we turn on custom shadow mapping through the scene manager (here, sceneMgr). It is recommended that this happen early as it may affect how certain resources are loaded.</p>
<div class="fragment"><div class="line"><span class="comment">// Use Ogre&#39;s custom shadow mapping ability</span></div><div class="line">sceneMgr-&gt;setShadowTexturePixelFormat(<a class="code" href="group___image.html#gga7e0353e7d36d4c2e8468641b7303d39ca2da3ec4fe727d552337e02069cd9efd9">PF_FLOAT32_R</a>);</div><div class="line">sceneMgr-&gt;setShadowTechnique( <a class="code" href="group___general.html#gga79dcd426d291c31072c1ad6f183715d6a8a2b43e30e6d8d590e6853e4f46b8103">SHADOWTYPE_TEXTURE_ADDITIVE</a> );</div><div class="line">sceneMgr-&gt;setShadowTextureCasterMaterial(<span class="stringliteral">&quot;CustomShadows/ShadowCaster&quot;</span>);</div><div class="line">sceneMgr-&gt;setShadowTextureReceiverMaterial(<span class="stringliteral">&quot;CustomShadows/ShadowReceiver&quot;</span>);</div><div class="line">sceneMgr-&gt;setShadowTextureSelfShadow(<span class="keyword">true</span>); </div><div class="line">sceneMgr-&gt;setShadowTextureSize(512);</div></div><!-- fragment --><p>The setShadowTechnique call is all that is required for Ogre’s default shadow mapping. In the code above, we have told <a class="el" href="namespace_ogre.html" title=" This source file is part of OGRE (Object-oriented Graphics Rendering Engine) For the latest info...">Ogre</a> to use the R channel of a floating point texture to store depth values. This tends to be a very portable method (over graphics cards and APIs). The sample sticks to using Ogre’s default of 512x512 shadow maps. Self-shadowing is turned on, but be warned that this will only work properly if appropriate depth biasing is also used. The example code will manually account for depth biasing via the method described above in section <a class="el" href="ShadowMappingOgre.html#DepthBias">Depth Biasing</a>. The shadow caster and shadow receiver materials are defined in a materials script. They tell <a class="el" href="namespace_ogre.html" title=" This source file is part of OGRE (Object-oriented Graphics Rendering Engine) For the latest info...">Ogre</a> which shaders to use when rendering shadow casters into the shadow map and rendering shadow receivers during shadow determination.</p>
<p>The CustomShadows.material material script is given below:</p>
<div class="fragment"><div class="line"><span class="comment">// Shadow Caster __________________________________________________</span></div><div class="line"></div><div class="line"></div><div class="line">vertex_program CustomShadows/ShadowCasterVP/Cg cg</div><div class="line">{</div><div class="line">    source customshadowcastervp.cg</div><div class="line">    entry_point main</div><div class="line">    profiles arbvp1 vs_2_0</div><div class="line"></div><div class="line">    default_params</div><div class="line">    {</div><div class="line">        param_named_auto uModelViewProjection worldviewproj_matrix</div><div class="line">    }</div><div class="line">}</div><div class="line"></div><div class="line">fragment_program CustomShadows/ShadowCasterFP/Cg cg</div><div class="line">{</div><div class="line">    source customshadowcasterfp.cg</div><div class="line">    entry_point main</div><div class="line">    profiles arbfp1 ps_2_0</div><div class="line"></div><div class="line">    default_params</div><div class="line">    {</div><div class="line">        param_named      uDepthOffset <span class="keywordtype">float</span>       1.0</div><div class="line">        param_named      uSTexWidth <span class="keywordtype">float</span>         512.0</div><div class="line">        param_named      uSTexHeight <span class="keywordtype">float</span>        512.0</div><div class="line">        param_named_auto uInvModelViewProjection  inverse_worldviewproj_matrix</div><div class="line">        param_named_auto uProjection              projection_matrix</div><div class="line">    }</div><div class="line">}</div><div class="line"></div><div class="line">vertex_program CustomShadows/ShadowCasterVP/GLSL glsl</div><div class="line">{</div><div class="line">    source customshadowcastervp.vert</div><div class="line"></div><div class="line">    default_params</div><div class="line">    {</div><div class="line">        param_named_auto uModelViewProjection worldviewproj_matrix</div><div class="line">    }</div><div class="line">}</div><div class="line"></div><div class="line">fragment_program CustomShadows/ShadowCasterFP/GLSL glsl</div><div class="line">{</div><div class="line">    source customshadowcasterfp.frag</div><div class="line"></div><div class="line">    default_params</div><div class="line">    {</div><div class="line">        param_named      uDepthOffset <span class="keywordtype">float</span>       1.0</div><div class="line">        param_named      uSTexWidth <span class="keywordtype">float</span>         512.0</div><div class="line">        param_named      uSTexHeight <span class="keywordtype">float</span>        512.0</div><div class="line">        param_named_auto uInvModelViewProjection  inverse_worldviewproj_matrix</div><div class="line">        param_named_auto uProjection              projection_matrix</div><div class="line">    }</div><div class="line">}</div><div class="line"></div><div class="line">vertex_program CustomShadows/ShadowCasterVP/HLSL hlsl</div><div class="line">{</div><div class="line">    source customshadowcastervp.hlsl</div><div class="line">    entry_point main</div><div class="line">    target vs_2_0</div><div class="line"></div><div class="line">    default_params</div><div class="line">    {</div><div class="line">        param_named_auto uModelViewProjection worldviewproj_matrix</div><div class="line">    }</div><div class="line">}</div><div class="line"></div><div class="line">fragment_program CustomShadows/ShadowCasterFP/HLSL hlsl</div><div class="line">{</div><div class="line">    source customshadowcasterfp.hlsl</div><div class="line">    entry_point main</div><div class="line">    target ps_2_0</div><div class="line"></div><div class="line">    default_params</div><div class="line">    {</div><div class="line">        param_named      uDepthOffset <span class="keywordtype">float</span>       1.0</div><div class="line">        param_named      uSTexWidth <span class="keywordtype">float</span>         512.0</div><div class="line">        param_named      uSTexHeight <span class="keywordtype">float</span>        512.0</div><div class="line">        param_named_auto uInvModelViewProjection  inverse_worldviewproj_matrix</div><div class="line">        param_named_auto uProjection              projection_matrix</div><div class="line">    }</div><div class="line">}</div><div class="line"></div><div class="line">material CustomShadows/ShadowCaster</div><div class="line">{</div><div class="line">    technique glsl</div><div class="line">    {</div><div class="line">        <span class="comment">// Z-write only pass</span></div><div class="line">        pass Z-write</div><div class="line">        {</div><div class="line">            vertex_program_ref CustomShadows/ShadowCasterVP/GLSL</div><div class="line">            {</div><div class="line">            }</div><div class="line">            fragment_program_ref CustomShadows/ShadowCasterFP/GLSL</div><div class="line">            {</div><div class="line">            }</div><div class="line">        }</div><div class="line">    }</div><div class="line"></div><div class="line">    technique hlsl</div><div class="line">    {</div><div class="line">        <span class="comment">// Z-write only pass</span></div><div class="line">        pass Z-write</div><div class="line">        {</div><div class="line">            <span class="comment">//Instead of using depth_bias, we&#39;ll be implementing it manually</span></div><div class="line"></div><div class="line">            vertex_program_ref CustomShadows/ShadowCasterVP/HLSL</div><div class="line">            {</div><div class="line">            }</div><div class="line">            fragment_program_ref CustomShadows/ShadowCasterFP/HLSL</div><div class="line">            {</div><div class="line">            }</div><div class="line">        }</div><div class="line">    }</div><div class="line"></div><div class="line">    technique cg</div><div class="line">    {</div><div class="line">        <span class="comment">// Z-write only pass</span></div><div class="line">        pass Z-write</div><div class="line">        {</div><div class="line">            <span class="comment">//Instead of using depth_bias, we&#39;ll be implementing it manually</span></div><div class="line"></div><div class="line">            vertex_program_ref CustomShadows/ShadowCasterVP/Cg</div><div class="line">            {</div><div class="line">            }</div><div class="line">            fragment_program_ref CustomShadows/ShadowCasterFP/Cg</div><div class="line">            {</div><div class="line">            }</div><div class="line">        }</div><div class="line">    }</div><div class="line">}</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">// Shadow Receiver ________________________________________________</span></div><div class="line"></div><div class="line">vertex_program CustomShadows/ShadowReceiverVP/Cg cg</div><div class="line">{</div><div class="line">    source customshadowreceivervp.cg</div><div class="line">    entry_point main</div><div class="line">    profiles arbvp1 vs_2_0</div><div class="line"></div><div class="line">    default_params</div><div class="line">    {</div><div class="line">        param_named_auto uModelViewProjection   worldviewproj_matrix</div><div class="line">        param_named_auto uLightPosition         light_position_object_space 0</div><div class="line">        param_named_auto uModel                 world_matrix</div><div class="line">        param_named_auto uTextureViewProjection texture_viewproj_matrix</div><div class="line">    }</div><div class="line">}</div><div class="line"></div><div class="line">fragment_program CustomShadows/ShadowReceiverFP/Cg cg</div><div class="line">{</div><div class="line">    source customshadowreceiverfp.cg</div><div class="line">    entry_point main</div><div class="line">    profiles arbfp1 ps_2_x</div><div class="line"></div><div class="line">    default_params</div><div class="line">    {</div><div class="line">        param_named uSTexWidth  <span class="keywordtype">float</span> 512.0</div><div class="line">        param_named uSTexHeight <span class="keywordtype">float</span> 512.0</div><div class="line">    }</div><div class="line">}</div><div class="line"></div><div class="line">vertex_program CustomShadows/ShadowReceiverVP/GLSL glsl</div><div class="line">{</div><div class="line">    source customshadowreceiver.vert</div><div class="line"></div><div class="line">    default_params</div><div class="line">    {</div><div class="line">        param_named_auto uModelViewProjection   worldviewproj_matrix</div><div class="line">        param_named_auto uLightPosition         light_position_object_space 0</div><div class="line">        param_named_auto uModel                 world_matrix</div><div class="line">        param_named_auto uTextureViewProjection texture_viewproj_matrix</div><div class="line">    }</div><div class="line">}</div><div class="line"></div><div class="line">fragment_program CustomShadows/ShadowReceiverFP/GLSL glsl</div><div class="line">{</div><div class="line">    source customshadowreceiver.frag</div><div class="line"></div><div class="line">    default_params</div><div class="line">    {</div><div class="line">        param_named uSTexWidth  <span class="keywordtype">float</span> 512.0</div><div class="line">        param_named uSTexHeight <span class="keywordtype">float</span> 512.0</div><div class="line">    }</div><div class="line">}</div><div class="line"></div><div class="line">vertex_program CustomShadows/ShadowReceiverVP/HLSL hlsl</div><div class="line">{</div><div class="line">    source customshadowreceivervp.hlsl</div><div class="line">    entry_point main</div><div class="line">    target vs_2_0</div><div class="line"></div><div class="line">    default_params</div><div class="line">    {</div><div class="line">        param_named_auto uModelViewProjection   worldviewproj_matrix</div><div class="line">        param_named_auto uLightPosition         light_position_object_space 0</div><div class="line">        param_named_auto uModel                 world_matrix</div><div class="line">        param_named_auto uTextureViewProjection texture_viewproj_matrix</div><div class="line">    }</div><div class="line">}</div><div class="line"></div><div class="line">fragment_program CustomShadows/ShadowReceiverFP/HLSL hlsl</div><div class="line">{</div><div class="line">    source customshadowreceiverfp.hlsl</div><div class="line">    entry_point main</div><div class="line">    target ps_3_0</div><div class="line"></div><div class="line">    default_params</div><div class="line">    {</div><div class="line">        param_named uSTexWidth  <span class="keywordtype">float</span> 512.0</div><div class="line">        param_named uSTexHeight <span class="keywordtype">float</span> 512.0</div><div class="line">    }</div><div class="line">}</div><div class="line"></div><div class="line">material CustomShadows/ShadowReceiver</div><div class="line">{</div><div class="line">    technique glsl</div><div class="line">    {</div><div class="line">        pass lighting</div><div class="line">        {</div><div class="line">            vertex_program_ref CustomShadows/ShadowReceiverVP/GLSL</div><div class="line">            {</div><div class="line">            }</div><div class="line"></div><div class="line">            fragment_program_ref CustomShadows/ShadowReceiverFP/GLSL</div><div class="line">            {</div><div class="line">                param_named uShadowMap <span class="keywordtype">int</span> 0</div><div class="line">            }</div><div class="line"></div><div class="line">            texture_unit ShadowMap</div><div class="line">            {</div><div class="line">                tex_address_mode clamp</div><div class="line">                filtering none</div><div class="line">            }</div><div class="line">        }</div><div class="line">    }</div><div class="line"></div><div class="line">    technique hlsl</div><div class="line">    {</div><div class="line">        pass lighting</div><div class="line">        {</div><div class="line">            vertex_program_ref CustomShadows/ShadowReceiverVP/HLSL</div><div class="line">            {</div><div class="line">            }</div><div class="line"></div><div class="line">            fragment_program_ref CustomShadows/ShadowReceiverFP/HLSL</div><div class="line">            {</div><div class="line">            }</div><div class="line"></div><div class="line">            <span class="comment">// we won&#39;t rely on hardware specific filtering of z-tests</span></div><div class="line">            texture_unit ShadowMap</div><div class="line">            {</div><div class="line">                tex_address_mode clamp</div><div class="line">                filtering none</div><div class="line">            }</div><div class="line">        }</div><div class="line">    }</div><div class="line"></div><div class="line">    technique cg</div><div class="line">    {</div><div class="line">        pass lighting</div><div class="line">        {</div><div class="line">            vertex_program_ref CustomShadows/ShadowReceiverVP/Cg</div><div class="line">            {</div><div class="line">            }</div><div class="line"></div><div class="line">            fragment_program_ref CustomShadows/ShadowReceiverFP/Cg</div><div class="line">            {</div><div class="line">            }</div><div class="line"></div><div class="line">            <span class="comment">// we won&#39;t rely on hardware specific filtering of z-tests</span></div><div class="line">            texture_unit ShadowMap</div><div class="line">            {</div><div class="line">                tex_address_mode clamp</div><div class="line">                filtering none</div><div class="line">            }</div><div class="line">        }</div><div class="line">    }</div><div class="line">}</div></div><!-- fragment --><p>Three techniques are presented, one for GLSL, one for HLSL, and one for Cg. We’ll present the GLSL code below. Note that while most of the shader files are direct translations of each other, DirectX HLSL shaders must handle percentage closest filtering slightly differently from OpenGL. OpenGL chooses the convention of having integers index sample centers whereas DirectX chooses integers to index sample corners. Also note the variable names in the shaders presented below are slightly different from those presented earlier in this document. This is due in part to the awkwardness of expressing subscripts in variable names and also in part because \(u_3\) is less evocative of depth than \(z\), etc. With minimal effort one can match the shader equations with those presented earlier. The code is presented here mostly to demonstrate how things fit together.</p>
<div class="fragment"><div class="line"><span class="comment">//</span></div><div class="line"><span class="comment">// shadowcastervp.vert</span></div><div class="line"><span class="comment">//</span></div><div class="line"><span class="comment">// This is an example vertex shader for shadow caster objects.  </span></div><div class="line"><span class="comment">//</span></div><div class="line"><span class="comment"></span></div><div class="line"></div><div class="line"><span class="comment">// I N P U T   V A R I A B L E S /////////////////////////////////</span></div><div class="line"></div><div class="line">uniform mat4 uModelViewProjection;   <span class="comment">// modelview projection matrix</span></div><div class="line"></div><div class="line"><span class="comment">// O U T P U T   V A R I A B L E S ///////////////////////////////</span></div><div class="line"></div><div class="line">varying vec4 pPosition;      <span class="comment">// post projection position coordinates</span></div><div class="line">varying vec4 pNormal;        <span class="comment">// normal in object space (to be interpolated)</span></div><div class="line">varying vec4 pModelPos;      <span class="comment">// position in object space (to be interpolated) </span></div><div class="line"></div><div class="line"><span class="comment">// M A I N ///////////////////////////////////////////////////////</span></div><div class="line"></div><div class="line"><span class="keywordtype">void</span> main()</div><div class="line">{</div><div class="line">    <span class="comment">// Transform vertex position into post projective (homogenous screen) space.</span></div><div class="line">    gl_Position = uModelViewProjection * gl_Vertex;</div><div class="line">    pPosition   = uModelViewProjection * gl_Vertex;</div><div class="line"></div><div class="line">    <span class="comment">// copy over data to interpolate using perspective correct interpolation</span></div><div class="line">    pNormal   = vec4(gl_Normal.x, gl_Normal.y, gl_Normal.z, 0.0);</div><div class="line">    pModelPos = gl_Vertex;</div><div class="line">}</div></div><!-- fragment --><p>This is a pretty standard vertex shader.</p>
<div class="fragment"><div class="line"><span class="comment">//</span></div><div class="line"><span class="comment">// shadowcasterfp.frag</span></div><div class="line"><span class="comment">//</span></div><div class="line"><span class="comment">// This is an example fragment shader for shadow caster objects.  </span></div><div class="line"><span class="comment">//</span></div><div class="line"><span class="comment"></span></div><div class="line"><span class="comment">// I N P U T   V A R I A B L E S ////////////////////////////////////////////////</span></div><div class="line"></div><div class="line"><span class="comment">// uniform constants</span></div><div class="line">uniform <span class="keywordtype">float</span> uDepthOffset;           <span class="comment">// offset amount (constant in eye space)</span></div><div class="line">uniform <span class="keywordtype">float</span> uSTexWidth;             <span class="comment">// shadow map texture width</span></div><div class="line">uniform <span class="keywordtype">float</span> uSTexHeight;            <span class="comment">// shadow map texture height</span></div><div class="line">uniform mat4  uInvModelViewProjection;<span class="comment">// inverse model-view-projection matrix</span></div><div class="line">uniform mat4  uProjection;            <span class="comment">// projection matrix</span></div><div class="line"></div><div class="line"><span class="comment">// per fragment inputs</span></div><div class="line">varying vec4 pPosition;      <span class="comment">// position of fragment (in homogeneous coordinates)</span></div><div class="line">varying vec4 pNormal;        <span class="comment">// un-normalized normal in object space</span></div><div class="line">varying vec4 pModelPos;      <span class="comment">// coordinates of model in object space at this point</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">// M A I N //////////////////////////////////////////////////////////////////////</span></div><div class="line"></div><div class="line"><span class="keywordtype">void</span> main(<span class="keywordtype">void</span>)</div><div class="line">{</div><div class="line">    <span class="comment">// compute the &quot;normalized device coordinates&quot; (no viewport applied yet)</span></div><div class="line">    vec4 postProj = pPosition / pPosition.w;</div><div class="line"></div><div class="line">    <span class="comment">// get the normalized normal of the geometry seen at this point</span></div><div class="line">    vec4 normal = normalize(pNormal);</div><div class="line"></div><div class="line"></div><div class="line">    <span class="comment">// -- Computing Depth Bias Quantities -----------------------------</span></div><div class="line"></div><div class="line">    <span class="comment">// We want to compute the &quot;depth slope&quot; of the polygon.  </span></div><div class="line">    <span class="comment">// This is the change in z value that accompanies a change in x or y on screen</span></div><div class="line">    <span class="comment">// such that the coordinates stay on the triangle. </span></div><div class="line">    <span class="comment">// The depth slope, dzlen below, is a measure of the uncertainty in our z value </span></div><div class="line">    <span class="comment">// Roughly, these equations come from re-arrangement of the product rule:</span></div><div class="line">    <span class="comment">// d(uq) = d(u)q + u d(q) --&gt; d(u) = 1/q * (d(uq) - u d(q))</span></div><div class="line">    vec4 duqdx = uInvModelViewProjection * vec4(1.0/uSTexWidth,0.0,0.0,0.0);</div><div class="line">    vec4 dudx  = pPosition.w * (duqdx - (pModelPos * duqdx.w));</div><div class="line">    vec4 duqdy = uInvModelViewProjection * vec4(0.0,1.0/uSTexHeight,0.0,0.0);</div><div class="line">    vec4 dudy  = pPosition.w * (duqdy - (pModelPos * duqdy.w));</div><div class="line">    vec4 duqdz = uInvModelViewProjection * vec4(0.0,0.0,1.0,0.0);</div><div class="line">    vec4 dudz  = pPosition.w * (duqdz - (pModelPos * duqdz.w));</div><div class="line">    <span class="comment">// The next relations come from the requirement dot(normal, displacement) = 0</span></div><div class="line">    <span class="keywordtype">float</span> denom = 1.0 / dot(normal.xyz, dudz.xyz);</div><div class="line">    vec2  dz = -  vec2( dot(normal.xyz, dudx.xyz) * denom , </div><div class="line">                         dot(normal.xyz, dudy.xyz) * denom );</div><div class="line">    <span class="keywordtype">float</span>  dzlen = max(abs(dz.x), abs(dz.y)); </div><div class="line"></div><div class="line"></div><div class="line">    <span class="comment">// We now compute the change in z that would signify a push in the z direction</span></div><div class="line">    <span class="comment">// by 1 unit in eye space.  Note that eye space z is related in a nonlinear way to</span></div><div class="line">    <span class="comment">// screen space z, so this is not just a constant.  </span></div><div class="line">    <span class="comment">// ddepth below is how much screen space z at this point would change for that push.</span></div><div class="line">    <span class="comment">// NOTE: computation of ddepth likely differs from OpenGL&#39;s glPolygonOffset &quot;unit&quot;</span></div><div class="line">    <span class="comment">//  computation, which is allowed to be vendor specific.</span></div><div class="line">    vec4 dpwdz = uProjection * vec4(0.0, 0.0, 1.0, 0.0);</div><div class="line">    vec4 dpdz = (dpwdz - (postProj * dpwdz.w)) / pPosition.w;</div><div class="line">    <span class="keywordtype">float</span>  ddepth = abs(dpdz.z);</div><div class="line"></div><div class="line">    <span class="comment">// -- End depth bias helper section --------------------------------   </span></div><div class="line"></div><div class="line">    <span class="comment">// We now compute the depth of the fragment.  This is the actual depth value plus</span></div><div class="line">    <span class="comment">// our depth bias.  The depth bias depends on how uncertain we are about the z value</span></div><div class="line">    <span class="comment">// plus some constant push in the z direction.  The exact coefficients to use are</span></div><div class="line">    <span class="comment">// up to you, but at least it should be somewhat intuitive now what the tradeoffs are.</span></div><div class="line">    <span class="keywordtype">float</span> depthval = postProj.z + (0.5 * dzlen)+ (uDepthOffset * ddepth);</div><div class="line">    depthval = (0.5 * depthval) + 0.5; <span class="comment">// put into [0,1] range instead of [-1,1] </span></div><div class="line"></div><div class="line">    gl_FragColor = vec4(depthval, depthval, depthval, 0.0);</div><div class="line">}</div></div><!-- fragment --><p>This shader computes the two depth bias pieces described in section <a class="el" href="ShadowMappingOgre.html#DepthBias">Depth Biasing</a>. These are used to offset the stored depth value. This is where the notation differs from above, but the translation is quite straightforward.</p>
<div class="fragment"><div class="line"><span class="comment">//</span></div><div class="line"><span class="comment">// shadowreceiver.vert</span></div><div class="line"><span class="comment">//</span></div><div class="line"><span class="comment"></span></div><div class="line"></div><div class="line"><span class="comment">// I N P U T   V A R I A B L E S /////////////////////////////////</span></div><div class="line"></div><div class="line">uniform mat4 uModelViewProjection;  <span class="comment">// modelview projection matrix</span></div><div class="line">uniform mat4 uModel;                    <span class="comment">// model matrix</span></div><div class="line">uniform mat4 uTextureViewProjection;    <span class="comment">// shadow map&#39;s view projection matrix</span></div><div class="line">uniform vec4 uLightPosition;            <span class="comment">// light position in object space</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">// O U T P U T   V A R I A B L E S ///////////////////////////////</span></div><div class="line"></div><div class="line">varying vec4   pShadowCoord;    <span class="comment">// vertex position in shadow map coordinates</span></div><div class="line">varying <span class="keywordtype">float</span>  pDiffuse;        <span class="comment">// diffuse shading value</span></div><div class="line"></div><div class="line"><span class="comment">// M A I N ///////////////////////////////////////////////////////</span></div><div class="line"></div><div class="line"><span class="keywordtype">void</span> main()</div><div class="line">{</div><div class="line">    <span class="comment">// compute diffuse shading</span></div><div class="line">    vec3 lightDirection = normalize(uLightPosition.xyz - gl_Vertex.xyz);</div><div class="line">    pDiffuse = dot(gl_Normal.xyz, lightDirection);</div><div class="line"></div><div class="line">    <span class="comment">// compute shadow map lookup coordinates</span></div><div class="line">    pShadowCoord = uTextureViewProjection * (uModel * gl_Vertex);</div><div class="line"></div><div class="line">    <span class="comment">// compute vertex&#39;s homogenous screen-space coordinates</span></div><div class="line">    <span class="comment">// Use following line if other passes use shaders</span></div><div class="line">    <span class="comment">//gl_Position = uModelViewProjection * gl_Vertex;   </span></div><div class="line">    gl_Position = ftransform(); <span class="comment">// uncomment if other passes use fixed function pipeline</span></div><div class="line">}</div></div><!-- fragment --><p>This is a pretty standard vertex shader as well. The ftransform() function guarantees the output matches the fixed function pipeline. If the objects you render use shaders instead of fixed function, then you should do so here as well.</p>
<div class="fragment"><div class="line"><span class="comment">//</span></div><div class="line"><span class="comment">// shadowreceiver.frag</span></div><div class="line"><span class="comment">//</span></div><div class="line"><span class="comment"></span></div><div class="line"><span class="comment">// I N P U T   V A R I A B L E S ////////////////////////////////////////////////</span></div><div class="line"></div><div class="line"><span class="comment">// uniform constants</span></div><div class="line">uniform sampler2D    uShadowMap;</div><div class="line">uniform <span class="keywordtype">float</span>        uSTexWidth;</div><div class="line">uniform <span class="keywordtype">float</span>        uSTexHeight;</div><div class="line"></div><div class="line"><span class="comment">// per fragment inputs</span></div><div class="line">varying vec4   pShadowCoord;    <span class="comment">// vertex position in shadow map coordinates</span></div><div class="line">varying <span class="keywordtype">float</span>  pDiffuse;        <span class="comment">// diffuse shading value</span></div><div class="line"></div><div class="line"><span class="comment">// M A I N //////////////////////////////////////////////////////////////////////</span></div><div class="line"></div><div class="line"><span class="keywordtype">void</span> main(<span class="keywordtype">void</span>)</div><div class="line">{</div><div class="line">    <span class="comment">// compute the shadow coordinates for texture lookup</span></div><div class="line">    <span class="comment">// NOTE: texture_viewproj_matrix maps z into [0,1] range, not [-1,1], so</span></div><div class="line">    <span class="comment">//  have to make sure shadow caster stores depth values with same convention.</span></div><div class="line">    vec4 scoord = pShadowCoord / pShadowCoord.w;</div><div class="line"></div><div class="line"></div><div class="line">    <span class="comment">// -- &quot;Percentage Closest Filtering&quot; ----------------------------------------- </span></div><div class="line"></div><div class="line">    <span class="comment">// One could use scoord.xy to look up the shadow map for depth testing, but</span></div><div class="line">    <span class="comment">// we&#39;ll be implementing a simple &quot;percentage closest filtering&quot; algorithm instead.</span></div><div class="line">    <span class="comment">// This mimics the behavior of turning on bilinear filtering on NVIDIA hardware</span></div><div class="line">    <span class="comment">// when also performing shadow comparisons.  This causes bilinear filtering of</span></div><div class="line">    <span class="comment">// depth tests.  Note that this is NOT the same as bilinear filtering the depth</span></div><div class="line">    <span class="comment">// values and then doing the depth comparison.  The two operations are not </span></div><div class="line">    <span class="comment">// commutative.  PCF is explicitly about filtering the test values since</span></div><div class="line">    <span class="comment">// testing filtered z values is often meaningless.  </span></div><div class="line"></div><div class="line">    <span class="comment">// Real percentage closest filtering should sample from the entire footprint</span></div><div class="line">    <span class="comment">// on the shadow map, not just seek the closest four sample points.  Such </span></div><div class="line">    <span class="comment">// an improvement is for future work.</span></div><div class="line"></div><div class="line"></div><div class="line">    <span class="comment">// NOTE: Assuming OpenGL convention for texture lookups with integers in centers.</span></div><div class="line">    <span class="comment">//  DX convention is to have integers mark sample corners</span></div><div class="line">    vec2 tcoord;</div><div class="line">    tcoord.x = (scoord.x * uSTexWidth) - 0.5;</div><div class="line">    tcoord.y = (scoord.y * uSTexHeight) - 0.5;</div><div class="line">    <span class="keywordtype">float</span> x0 = floor(tcoord.x);</div><div class="line">    <span class="keywordtype">float</span> x1 = ceil(tcoord.x);</div><div class="line">    <span class="keywordtype">float</span> fracx = fract(tcoord.x);</div><div class="line">    <span class="keywordtype">float</span> y0 = floor(tcoord.y);</div><div class="line">    <span class="keywordtype">float</span> y1 = ceil(tcoord.y);</div><div class="line">    <span class="keywordtype">float</span> fracy = fract(tcoord.y);</div><div class="line"></div><div class="line">    <span class="comment">// sample coordinates in [0,1]^2 domain</span></div><div class="line">    vec2 t00, t01, t10, t11;</div><div class="line">    <span class="keywordtype">float</span> invWidth  = 1.0 / uSTexWidth;</div><div class="line">    <span class="keywordtype">float</span> invHeight = 1.0 / uSTexHeight;</div><div class="line">    t00 = float2((x0+0.5) * invWidth, (y0+0.5) * invHeight);</div><div class="line">    t10 = float2((x1+0.5) * invWidth, (y0+0.5) * invHeight);</div><div class="line">    t01 = float2((x0+0.5) * invWidth, (y1+0.5) * invHeight);</div><div class="line">    t11 = float2((x1+0.5) * invWidth, (y1+0.5) * invHeight);</div><div class="line"></div><div class="line">    <span class="comment">// grab the samples</span></div><div class="line">    <span class="keywordtype">float</span> z00 = texture2D(uShadowMap, t00).x;</div><div class="line">    <span class="keywordtype">float</span> viz00 = (z00 &lt;= scoord.z) ? 0.0 : 1.0;</div><div class="line">    <span class="keywordtype">float</span> z01 = texture2D(uShadowMap, t01).x;</div><div class="line">    <span class="keywordtype">float</span> viz01 = (z01 &lt;= scoord.z) ? 0.0 : 1.0;</div><div class="line">    <span class="keywordtype">float</span> z10 = texture2D(uShadowMap, t10).x;</div><div class="line">    <span class="keywordtype">float</span> viz10 = (z10 &lt;= scoord.z) ? 0.0 : 1.0;</div><div class="line">    <span class="keywordtype">float</span> z11 = texture2D(uShadowMap, t11).x;</div><div class="line">    <span class="keywordtype">float</span> viz11 = (z11 &lt;= scoord.z) ? 0.0 : 1.0;</div><div class="line"></div><div class="line">    <span class="comment">// determine that all geometry outside the shadow test frustum is lit</span></div><div class="line">    viz00 = ((abs(t00.x - 0.5) &lt;= 0.5) &amp;&amp; (abs(t00.y - 0.5) &lt;= 0.5)) ? viz00 : 1.0;</div><div class="line">    viz01 = ((abs(t01.x - 0.5) &lt;= 0.5) &amp;&amp; (abs(t01.y - 0.5) &lt;= 0.5)) ? viz01 : 1.0;</div><div class="line">    viz10 = ((abs(t10.x - 0.5) &lt;= 0.5) &amp;&amp; (abs(t10.y - 0.5) &lt;= 0.5)) ? viz10 : 1.0; </div><div class="line">    viz11 = ((abs(t11.x - 0.5) &lt;= 0.5) &amp;&amp; (abs(t11.y - 0.5) &lt;= 0.5)) ? viz11 : 1.0;</div><div class="line"></div><div class="line">    <span class="comment">// bilinear filter test results</span></div><div class="line">    <span class="keywordtype">float</span> v0 = (1.0 - fracx) * viz00 + fracx * viz10;</div><div class="line">    <span class="keywordtype">float</span> v1 = (1.0 - fracx) * viz01 + fracx * viz11;</div><div class="line">    <span class="keywordtype">float</span> visibility = (1.0 - fracy) * v0 + fracy * v1;</div><div class="line"></div><div class="line">    <span class="comment">// ------------------------------------------------------------------------------</span></div><div class="line"></div><div class="line">    <span class="comment">// Non-PCF code (comment out above section and uncomment the following three lines)</span></div><div class="line"></div><div class="line">    <span class="comment">//float zvalue = texture2D(uShadowMap, scoord.xy).x;</span></div><div class="line">    <span class="comment">//float visibility = (zvalue &lt;= scoord.z) ? 0.0 : 1.0;</span></div><div class="line">    <span class="comment">//visibility = ((abs(scoord.x - 0.5) &lt;= 0.5) &amp;&amp; (abs(scoord.y - 0.5) &lt;= 0.5)) </span></div><div class="line">    <span class="comment">//             ? visibility : 1.0;</span></div><div class="line"></div><div class="line">    <span class="comment">// ------------------------------------------------------------------------------</span></div><div class="line"></div><div class="line">    visibility *= pDiffuse;</div><div class="line">    gl_FragColor = vec4(visibility, visibility, visibility, 0.0);</div><div class="line">}</div></div><!-- fragment --><p>This file implements percentage closest filtering. To use unfiltered shadow mapping, comment out the PCF block as noted and uncomment the Non-PCF block. Note that after doing this, the uSTexWidth and uSTexHeight variables are likely to be optimized away and so you should uncomment these variables in the materials script as well.</p>
<p>The following shows how to activate plane optimal shadow mapping given some pointer to a MovablePlane and a pointer to a light.</p>
<div class="fragment"><div class="line">PlaneOptimalShadowCameraSetup *planeOptShadowCamera = </div><div class="line">                               <span class="keyword">new</span> PlaneOptimalShadowCameraSetup(movablePlane);</div><div class="line">Entity *movablePlaneEntity = sceneMgr-&gt;createEntity( <span class="stringliteral">&quot;movablePlane&quot;</span>, <span class="stringliteral">&quot;plane.mesh&quot;</span> );</div><div class="line">SceneNode *movablePlaneNode = </div><div class="line">             sceneMgr-&gt;getRootSceneNode()-&gt;createChildSceneNode(<span class="stringliteral">&quot;MovablePlaneNode&quot;</span>);</div><div class="line">movablePlaneNode-&gt;attachObject(movablePlaneEntity);</div><div class="line">SharedPtr&lt;ShadowCameraSetup&gt; planeOptPtr(planeOptShadowCamera);</div><div class="line">light-&gt;setCustomShadowCameraSetup(planeOptPtr);</div></div><!-- fragment --> </div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="tutorials.html">Tutorials</a></li>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.11 </li>
  </ul>
</div>
</body>
</html>
